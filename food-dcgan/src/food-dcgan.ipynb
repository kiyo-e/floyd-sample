{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, Convolution2D\n",
    "from keras.layers.core import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import math\n",
    "\n",
    "import os\n",
    "from scipy import ndimage, misc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=1024, input_dim=100))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dense(128*16*16))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Reshape((16, 16, 128), input_shape=(128*16*16,)))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2D(64, (5, 5), padding=\"same\"))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2D(3, (5, 5), padding=\"same\"))\n",
    "    model.add(Activation('tanh'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(\n",
    "                        64, (5, 5),\n",
    "                        padding=\"same\",\n",
    "                        input_shape=(64, 64, 3)))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(128, (5, 5)))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator_containing_discriminator(generator, discriminator):\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    discriminator.trainable = False\n",
    "    model.add(discriminator)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_images(generated_images):\n",
    "    num = generated_images.shape[0]\n",
    "    width = int(math.sqrt(num))\n",
    "    height = int(math.ceil(float(num)/width))\n",
    "    shape = generated_images.shape[1:]\n",
    "    image = np.zeros((height*shape[0], width*shape[1], shape[2]),\n",
    "                     dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
    "            img[ :, :, :]\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    discriminator = discriminator_model()\n",
    "    generator = generator_model()\n",
    "    \n",
    "    \n",
    "    discriminator_on_generator = \\\n",
    "        generator_containing_discriminator(generator, discriminator)\n",
    "        \n",
    "        \n",
    "        \n",
    "    d_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "    g_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "    \n",
    "    \n",
    "    generator.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "    \n",
    "    discriminator_on_generator.compile(\n",
    "        loss='binary_crossentropy', optimizer=g_optim)\n",
    "    \n",
    "    discriminator.trainable = True\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=d_optim)\n",
    "    \n",
    "    noise = np.zeros((BATCH_SIZE, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is 0\n",
      "Found 100995 images belonging to 101 classes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot copy sequence with size 1000 to array axis with dimension 999",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-13927415fcfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch is\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     for X_train in test_datagen.flow_from_directory('../input/images', target_size=(64, 64), \n\u001b[0;32m----> 5\u001b[0;31m                                                              color_mode=\"rgb\", batch_size=BATCH_SIZE, class_mode=None):\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of batches\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links)\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0msave_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             follow_links=follow_links)\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m             \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilenames\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot copy sequence with size 1000 to array axis with dimension 999"
     ]
    }
   ],
   "source": [
    "    for epoch in range(100):\n",
    "        index = 0\n",
    "        print(\"Epoch is\", epoch)\n",
    "        for X_train in test_datagen.flow_from_directory('../input/images', target_size=(64, 64), \n",
    "                                                                 color_mode=\"rgb\", batch_size=BATCH_SIZE, class_mode=None):\n",
    "\n",
    "            print(\"Number of batches\", index)\n",
    "            index += 1\n",
    "            # BATCH_SIZEは文字通りのbatch size\n",
    "            #for index in range(int(X_train.shape[0]/BATCH_SIZE)):\n",
    "            for i in range(BATCH_SIZE):\n",
    "                  noise[i, :] = np.random.uniform(-1, 1, 100)\n",
    "                #image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "            \n",
    "                #ランダムに生成したnosizeで予測\n",
    "            generated_images = generator.predict(noise, verbose=0)\n",
    "            \n",
    "                # 生成したものを20個ごとに保存しているだけ\n",
    "            if index % 20 == 0:\n",
    "                image = combine_images(generated_images)\n",
    "                image = image*127.5+127.5\n",
    "                Image.fromarray(image.astype(np.uint8)).save(\n",
    "                    \"../output/\"+str(epoch)+\"_\"+str(index)+\".png\")\n",
    "\n",
    "                    \n",
    "                # 参考にした画像を保存\n",
    "            #image_batch=np.transpose(X_train,(0,2,3,1))\n",
    "\n",
    "            image_batch=X_train\n",
    "            if index % 20 == 0:\n",
    "                image_real = combine_images(image_batch)\n",
    "                image_real = image_real*127.5+127.5\n",
    "                Image.fromarray(image_real.astype(np.uint8)).save(\n",
    "                    \"../output/target\"+str(epoch)+\"_\"+str(index)+\".png\")\n",
    "            \n",
    "            X = np.concatenate((image_batch, generated_images))\n",
    "            y = [1] * int(len(X) / 2) + [0] * int(len(X) / 2)\n",
    "            \n",
    "            \n",
    "                #discriminatorで学習\n",
    "            d_loss = discriminator.train_on_batch(X, y)\n",
    "            print(\"batch %d d_loss : %f\" % (index, d_loss))\n",
    "            \n",
    "            \n",
    "            for i in range(BATCH_SIZE):\n",
    "                noise[i, :] = np.random.uniform(-1, 1, 100)\n",
    "                \n",
    "                # discriminatorの学習が進まないように修正\n",
    "            discriminator.trainable = False\n",
    "            \n",
    "            \n",
    "            g_loss = discriminator_on_generator.train_on_batch(\n",
    "                noise, [1] * BATCH_SIZE)\n",
    "            \n",
    "                # discriminatorが再度学習するように\n",
    "            discriminator.trainable = True\n",
    "            \n",
    "            print(\"batch %d g_loss : %f\" % (index, g_loss))\n",
    "            if index % 10 == 9:\n",
    "                generator.save_weights('../output/generator', True)\n",
    "                discriminator.save_weights('../output/discriminator', True)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
